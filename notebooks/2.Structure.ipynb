{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Structure (Part 1)\n",
    "In this notebook we will take the data we prepared and that is now found in <code>cleaned_logs/</code>. At the end of this notebook, we will end up with several files that are structured with meaningful data analysis in mind:\n",
    "\n",
    "- <code>ping.csv</code>\n",
    "- <code>routing.csv</code>\n",
    "- <code>mesh.csv</code>\n",
    "- <code>wifi.csv</code>\n",
    "\n",
    "In the next notebook we will further add granularity to support various analysis purposes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Master Files\n",
    "#### 2.1.1 Wifi\n",
    "The `wifi` file only consist of `no_of_connections` and therefore the final file will consist of three columns: \n",
    "\n",
    "- `timestamp`\n",
    "- `node_ip`\n",
    "- `no_of_connections`\n",
    "\n",
    "<i><font style='color:red'>NOTE: it's not clear if the files share the timestamp, so merge files later keeping this in mind.</font></i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _wifi_clients(node_ip):\n",
    "\n",
    "    # open and read the file for the given node\n",
    "    f = open('cleaned_logs/' + node_ip + '_wifi.log', 'r')\n",
    "    out = f.readlines()\n",
    "\n",
    "    final = []\n",
    "\n",
    "    # iterate through each record to clean it up\n",
    "    for i in out:\n",
    "        \n",
    "        # remove extra markings\n",
    "        i = i.strip()\n",
    "\n",
    "        # the records start with date so store that first\n",
    "        if i.startswith('###'):\n",
    "            date = ' '.join(i.split()[2:])\n",
    "            \n",
    "        # then take the actual values and combine both into single record\n",
    "        elif 'Number' in i:\n",
    "            data = i.split(':')[-1]\n",
    "            final.append([node_ip, date, data])\n",
    "            \n",
    "    # return the cleaned records\n",
    "    return final\n",
    "\n",
    "def create_connections_csv():\n",
    "\n",
    "    import pandas as pd\n",
    "    import os\n",
    "\n",
    "    # get a list of unique node IPs\n",
    "    nodes = []\n",
    "    for i in os.popen('ls cleaned_logs').readlines():\n",
    "        i = i.strip()\n",
    "        nodes.append(i.split('_')[0])\n",
    "        nodes = list(set(nodes))\n",
    "\n",
    "    # go through files for each and clean records\n",
    "    out = []\n",
    "    for node in nodes:\n",
    "        data = _wifi_clients(node)\n",
    "        out += data\n",
    "\n",
    "    # create a dataframe from the records\n",
    "    wifi_df = pd.DataFrame(out)\n",
    "    wifi_df.columns = ['node_ip', 'timestamp', 'no_of_connections']\n",
    "    wifi_df.no_of_connections = wifi_df.no_of_connections.astype(int)\n",
    "    \n",
    "    # convert the timestamp string into datetime column\n",
    "    wifi_df.timestamp = pd.DatetimeIndex(wifi_df.timestamp)\n",
    "\n",
    "    # export to CSV in pwd\n",
    "    wifi_df.to_csv('wifi.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_connections_csv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.2 Ping\n",
    "The `ping` file only consist of several metrics that are returned from a standard ping command. Like all the other files, it also consist of `node_ip` and `timestamp`. Comprehensive list of the columns in ping file: \n",
    "\n",
    "- `min`\n",
    "- `avg`\n",
    "- `max`\n",
    "- `std`\n",
    "- `node_ip`\n",
    "- `no_of_connections`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ping_csv():\n",
    "    \n",
    "    import pandas as pd\n",
    "    import os\n",
    "\n",
    "    # get a list of unique node IPs\n",
    "    nodes = []\n",
    "    for i in os.popen('ls cleaned_logs').readlines():\n",
    "        i = i.strip()\n",
    "        nodes.append(i.split('_')[0])\n",
    "        nodes = list(set(nodes))\n",
    "\n",
    "    # go through files for each and clean records\n",
    "    out = []\n",
    "    for node in nodes:\n",
    "        data = _ping_stats(node)\n",
    "        out += data\n",
    "\n",
    "    \n",
    "    # create a dataframe from the records\n",
    "    ping_df = pd.DataFrame(out)\n",
    "    ping_df.columns = ['node_ip', 'timestamp', 'min', 'avg', 'max', 'mdev']\n",
    "    ping_df[['min', 'avg', 'max', 'mdev']] = ping_df[['min', 'avg', 'max', 'mdev']].astype(float)\n",
    "    \n",
    "    # convert the timestamp string into datetime column\n",
    "    ping_df.timestamp = pd.DatetimeIndex(ping_df.timestamp)\n",
    "\n",
    "    # export to CSV in pwd\n",
    "    ping_df.to_csv('ping.csv', index=None)\n",
    "\n",
    "\n",
    "# helper function for create_ping_csv()\n",
    "def _ping_stats(node_ip):\n",
    "\n",
    "    # open and read the file for the given node\n",
    "    f = open('cleaned_logs/' + node_ip + '_ping.log', 'r')\n",
    "    out = f.readlines()\n",
    "\n",
    "    final = []\n",
    "    \n",
    "    # iterate through each record to clean it up\n",
    "    for i in out:\n",
    "        \n",
    "        # remove extra markings\n",
    "        i = i.strip()\n",
    "\n",
    "        # the records start with date so store that first\n",
    "        if i.startswith('###'):\n",
    "            date = ' '.join(i.split()[2:])\n",
    "        \n",
    "        # then take the actual values and combine both into single record\n",
    "        elif 'rtt' in i:\n",
    "            data = i.split('=')[-1].split(' ')[1]\n",
    "            data = data.split('/')\n",
    "            final.append([node_ip, date] + data)\n",
    "    \n",
    "    # return the cleaned records\n",
    "    return final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.3 Mesh\n",
    "The `mesh` file consist of many metrics, all associated with the Quality-of-Service (QOS) aspect of the mesh network:\n",
    "\n",
    "- `node_ip`\n",
    "- `timestamp`\n",
    "- `node_mac`\n",
    "- `signal_dbm`\n",
    "- `noise_dbm`\n",
    "- `ago_ms`\n",
    "- `rx_mbps`\n",
    "- `rx_MCS`\n",
    "- `rx_MHz`\n",
    "- `rx_pkts`\n",
    "- `tx_mbps`\n",
    "- `tx_MCS`\n",
    "- `tx_MHz`\n",
    "- `tx_pkts`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mesh_csv():\n",
    "    \n",
    "    import os\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "\n",
    "    # get the node IPs\n",
    "    nodes = list(set([i.split('_')[0] for i in os.popen('ls cleaned_logs/').readlines()]))\n",
    "\n",
    "    # clean up the records for each node\n",
    "    out = []\n",
    "    for node in nodes:\n",
    "        data = _mesh(node)\n",
    "        out += data\n",
    "    \n",
    "    # create a dataframe from the cleaned records\n",
    "    mesh_df = pd.DataFrame(out)\n",
    "    mesh_df.columns = ['node_ip',\n",
    "                       'timestamp',\n",
    "                       'node_mac',\n",
    "                       'signal_dbm',\n",
    "                       'noise_dbm',\n",
    "                       'ago_ms',\n",
    "                       'rx_mbps',\n",
    "                       'rx_MCS',\n",
    "                       'rx_MHz',\n",
    "                       'rx_pkts',\n",
    "                       'tx_mbps',\n",
    "                       'tx_MCS',\n",
    "                       'tx_MHz',\n",
    "                       'tx_pkts']\n",
    "\n",
    "    # clean up various mess from the original records\n",
    "    mesh_df = mesh_df.replace('NA', np.nan)\n",
    "    mesh_df = mesh_df.replace('unknown', np.nan)\n",
    "    mesh_df = mesh_df.replace('ms', np.nan)\n",
    "    mesh_df = mesh_df.replace('dBm', np.nan)\n",
    "    mesh_df.rx_MHz = mesh_df.rx_MHz.str.replace('MHz', '')\n",
    "    mesh_df.tx_MHz = mesh_df.tx_MHz.str.replace('MHz', '')\n",
    "    mesh_df.rx_MCS = mesh_df.rx_MCS.str.replace(',', '')\n",
    "    mesh_df.tx_MCS = mesh_df.tx_MCS.str.replace(',', '')\n",
    "\n",
    "    # convert to float what readily converts\n",
    "    for col in mesh_df.columns:\n",
    "        try:\n",
    "            mesh_df[col] = mesh_df[col].astype(float)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    # drop bad records\n",
    "    mesh_df = mesh_df[~mesh_df.timestamp.str.contains('###')]\n",
    "\n",
    "    # convert timestamp string to datetime column\n",
    "    mesh_df.timestamp = pd.DatetimeIndex(mesh_df.timestamp)\n",
    "\n",
    "    # export to csv\n",
    "    mesh_df.to_csv('mesh.csv', index=None)\n",
    "\n",
    "\n",
    "def _mesh(node_ip):\n",
    "\n",
    "    f = open('cleaned_logs/' + node_ip + '_mesh.log', 'r')\n",
    "    out = f.readlines()\n",
    "\n",
    "    final = []\n",
    "\n",
    "    for i in out:\n",
    "\n",
    "        i = i.strip()\n",
    "\n",
    "        if i.startswith('###'):\n",
    "            date = ' '.join(i.split()[2:])\n",
    "        \n",
    "        elif 'ms ago' in i:\n",
    "            header = i.split()\n",
    "            header = [header[0], header[1], header[4], header[8]]\n",
    "            \n",
    "        elif 'RX:' in i:\n",
    "            rx = i.split()\n",
    "            try:\n",
    "                rx = [rx[1], rx[4], rx[5], rx[6]]\n",
    "            except IndexError:\n",
    "                rx = ['NA', 'NA', 'NA', 'NA']\n",
    "            \n",
    "        elif 'TX:' in i:\n",
    "            tx = i.split()\n",
    "            try:\n",
    "                tx = [tx[1], tx[4], tx[5], tx[6]]\n",
    "            except IndexError:\n",
    "                tx = ['NA', 'NA', 'NA', 'NA']\n",
    "            \n",
    "            final.append([node_ip, date] + header + rx + tx)\n",
    "            \n",
    "    return final"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
